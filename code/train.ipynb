{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from deep_traffic_generation.fcvae import FCVAE\n",
    "\n",
    "from deep_traffic_generation.core.abstract import AE, VAE\n",
    "from deep_traffic_generation.core.datasets import TrafficDataset\n",
    "from deep_traffic_generation.core.lsr import VampPriorLSR, NormalLSR, ExemplarLSR\n",
    "from deep_traffic_generation.core.networks import FCN, RNN, TCN\n",
    "from deep_traffic_generation.core.utils import get_dataloaders\n",
    "\n",
    "# seed\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------\n",
    "# args\n",
    "# ------------\n",
    "cls = FCVAE\n",
    "dataset_cls = TrafficDataset\n",
    "data_shape = \"linear\"\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--train_ratio\", dest=\"train_ratio\", type=float, default=0.8\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--val_ratio\", dest=\"val_ratio\", type=float, default=0.2\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", dest=\"batch_size\", type=int, default=1000\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--test_batch_size\",\n",
    "    dest=\"test_batch_size\",\n",
    "    type=int,\n",
    "    default=None,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--early_stop\", dest=\"early_stop\", type=int, default=None\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--gradient_clip_val\", dest=\"gradient_clip_val\", type=float, default=0\n",
    ")\n",
    "parser = dataset_cls.add_argparse_args(parser)\n",
    "parser, _ = cls.add_model_specific_args(parser)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# Update the args object with the provided values\n",
    "args.data_path = \"../data/dataset.parquet\"\n",
    "args.h_dims = [64, 64, 64]\n",
    "args.encoding_dim = 8\n",
    "args.lr_step_size = 200\n",
    "args.lr = 0.001\n",
    "args.lrgamma = 0.5\n",
    "args.dropout = 0.2\n",
    "args.features = [\"track\", \"groundspeed\", \"altitude\", \"timedelta\"]\n",
    "args.info_features = [\"latitude\", \"longitude\"]\n",
    "args.info_index = -1\n",
    "args.kld_coef = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------\n",
    "# data\n",
    "# ------------\n",
    "dataset = dataset_cls.from_file(\n",
    "    args.data_path,\n",
    "    features=args.features,\n",
    "    shape=data_shape,\n",
    "    scaler=MinMaxScaler(feature_range=(-1, 1)),\n",
    "    info_params={\"features\": args.info_features, \"index\": args.info_index},\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    dataset,\n",
    "    args.train_ratio,\n",
    "    args.val_ratio,\n",
    "    args.batch_size,\n",
    "    args.test_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------\n",
    "# logger\n",
    "# ------------\n",
    "tb_logger = TensorBoardLogger(\n",
    "    \"lightning_logs/\",\n",
    "    name=args.network_name,\n",
    "    default_hp_metric=False,\n",
    "    log_graph=True,\n",
    ")\n",
    "\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "model = cls(\n",
    "    dataset_params=dataset.parameters,\n",
    "    config=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params | In sizes | Out sizes\n",
      "---------------------------------------------------------------\n",
      "0 | encoder   | FCN       | 59.8 K | [1, 800] | [1, 64]  \n",
      "1 | lsr       | NormalLSR | 1.1 K  | [1, 64]  | ?        \n",
      "2 | decoder   | FCN       | 61.3 K | [1, 8]   | [1, 800] \n",
      "3 | out_activ | Identity  | 0      | [1, 800] | [1, 800] \n",
      "---------------------------------------------------------------\n",
      "122 K     Trainable params\n",
      "16        Non-trainable params\n",
      "122 K     Total params\n",
      "0.489     Total estimated model params size (MB)\n",
      "c:\\Users\\zakaria\\mambaforge\\envs\\traffic\\lib\\site-packages\\torch\\jit\\_trace.py:976: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
      "  module._c._create_method_from_trace(\n",
      "c:\\Users\\zakaria\\mambaforge\\envs\\traffic\\lib\\site-packages\\torch\\jit\\_trace.py:1001: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%eps : Float(1, 8, strides=[8, 1], requires_grad=0, device=cuda:0) = aten::normal(%197, %205, %206) # c:\\Users\\zakaria\\mambaforge\\envs\\traffic\\lib\\site-packages\\torch\\distributions\\utils.py:46:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  _check_trace(\n",
      "c:\\Users\\zakaria\\mambaforge\\envs\\traffic\\lib\\site-packages\\torch\\jit\\_trace.py:1001: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 8 / 8 (100.0%)\n",
      "Greatest absolute difference: 3.0505913496017456 at index (0, 4) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 5.737061952323289 at index (0, 2) (up to 1e-05 allowed)\n",
      "  _check_trace(\n",
      "c:\\Users\\zakaria\\mambaforge\\envs\\traffic\\lib\\site-packages\\torch\\jit\\_trace.py:1001: TracerWarning: Output nr 2. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 800 / 800 (100.0%)\n",
      "Greatest absolute difference: 0.09430953860282898 at index (0, 422) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 96.77313011148281 at index (0, 110) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd708182e1f442782c1badc625af971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Trainer.test() got an unexpected keyword argument 'test_dataloaders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m# ------------\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# testing\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# ------------\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m test_loader \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     trainer\u001b[39m.\u001b[39;49mtest(test_dataloaders\u001b[39m=\u001b[39;49mtest_loader)\n",
      "\u001b[1;31mTypeError\u001b[0m: Trainer.test() got an unexpected keyword argument 'test_dataloaders'"
     ]
    }
   ],
   "source": [
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"hp/valid_loss\")\n",
    "# checkpoint_callback = ModelCheckpoint()\n",
    "if args.early_stop is not None:\n",
    "    early_stopping = EarlyStopping(\n",
    "        \"hp/valid_loss\", patience=args.early_stop\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        gradient_clip_val=args.gradient_clip_val,\n",
    "        callbacks=[checkpoint_callback, early_stopping],\n",
    "        logger=tb_logger,\n",
    "        # deterministic=True,\n",
    "    )\n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        gradient_clip_val=args.gradient_clip_val,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        logger=tb_logger,\n",
    "        # deterministic=True,\n",
    "    )\n",
    "\n",
    "if val_loader is not None:\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "else:\n",
    "    trainer.fit(model, train_loader)\n",
    "\n",
    "# ------------\n",
    "# testing\n",
    "# ------------\n",
    "if test_loader is not None:\n",
    "    trainer.test(test_dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
